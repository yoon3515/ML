{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도의 문제점 살펴보기\n",
    "**정확도(Acuuracy)** = 예측 결과가 동일한 데이터 건수 / 모든 예측 데이터 건수\n",
    "- 불균형한 레이블값 분포에서 ML 모델의 선능을 판단할 경우 적합한 지표가 아님\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 레이블값이 골고루 분포 돼있는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('c:/my_web/machine_lecture/titanic_train.csv')\n",
    "titanic.head()\n",
    "print(titanic['Sex'].value_counts())\n",
    "print()\n",
    "print(titanic['Survived'].value_counts()) # 레이블 값이 고루 분포 돼있음 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanic 데이터에서 남성(1)은 사망(0), 여성(0)은 생존(1)으로 예측하는 **이진분류기** 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator) :\n",
    "    # fit() 메소드는 아무것도 학습하지 않음 \n",
    "    def fit(self, X, y = None) :\n",
    "        pass\n",
    "    \n",
    "    # predict() 메소드는 단순히 sex feature가 남자(1)이면 사망(0), 여자(0)이면 생존(1)으로 예측\n",
    "    def predict(self, X) :\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1 :\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        return pred\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 처리 함수\n",
    "def fillna(df) :\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "# 불필요한 속성 제거하는 함수 \n",
    "def drop_features(df) :\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "# 인코딩 함수 \n",
    "def enco_features(df) :\n",
    "    df['Cabin'] = df['Cabin'].str[:1] # 맨 앞 알파벳만 가져오기\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에 생성한 함수 전부 불러오는 전처리 함수 생성\n",
    "def process_features(df) :\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = enco_features(df)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩, 가공, 학습, 예측, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 :  0.8296\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "titanic = pd.read_csv('c:/my_web/machine_lecture/titanic_train.csv')\n",
    "data = titanic.drop('Survived', axis = 1)\n",
    "target = titanic['Survived']\n",
    "\n",
    "# 전처리 \n",
    "data = process_features(data)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 11,\n",
    "                                                    stratify = target)\n",
    "\n",
    "# 데이터 학습 \n",
    "mdc = MyDummyClassifier()\n",
    "mdc.fit(X_train, y_train) \n",
    "\n",
    "# 예측\n",
    "pred = mdc.predict(X_test) \n",
    "\n",
    "# 평가 \n",
    "print('Dummy Classifier의 정확도는 : {0: .4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 레이블 값 분포가 불균형한 경우"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 전부 0으로 분류(예측)되는 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFakeClassifier(BaseEstimator) :\n",
    "    def fit(self, X, y) :\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X) :\n",
    "        return np.zeros((len(X), 1), dtype = bool)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런의 내장 데이터셋인 load_digits()를 이용하여 MNIST데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "data.shape : (1797, 64)\n",
      "\n",
      "[0 1 2 ... 8 9 8]\n",
      "target.shape : (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print('data.shape :', digits.data.shape)\n",
    "print()\n",
    "print(digits.target)\n",
    "print('target.shape :', digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "1    182\n",
       "5    182\n",
       "4    181\n",
       "6    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.DataFrame(digits.target)\n",
    "df_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- digits번호가 7번이면 **True**이고 --> **1**로 변환\n",
    "- 7이 아니면 **False**이고 --> **0**으로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (digits.target == 7).astype(int)\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y,\n",
    "                                                    random_state = 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블 데이터 분포도 확인 --> 불균형함을 알 수 있음 (0이 훨씬 많음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 종속변수 크기 : (450,)\n",
      "테스트 종속변수 0과 1의 분포도 :\n",
      " 0    405\n",
      "1     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('테스트 종속변수 크기 :', y_test.shape)\n",
    "print('테스트 종속변수 0과 1의 분포도 :\\n', pd.Series(y_test).value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MyFakeClassifier로 학습/예측/정확도 평가해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 예측(분류)을 0으로 하여도 정확도는 :  0.900\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "\n",
    "# 예측(분류)\n",
    "fake_pred = fakeclf.predict(X_test) # 데이터가 전부 0으로 예측된다. \n",
    "\n",
    "# 정확도 평가\n",
    "print('모든 예측(분류)을 0으로 하여도 정확도는 : {: .3f}'.format(accuracy_score(y_test, fake_pred)))\n",
    "# 모든 예측을 0으로 하여도 실제 데이터의 분포가 0으로 치우쳐져 있기 때문에 예측과 실제가 일치할 확률이 90퍼나 된다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 결론 : 이진분류 종속변수의 데이터 분포가 한쪽으로 치우칠 경우 (0이나 1로 치우칠 경우) \n",
    "#### 정확도로 평가하는것은 부적절하다.\n",
    "- 정확도의 한계를 보완하기 위한 평가지표를 알아보자"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix (오차행렬)\n",
    "오차행렬 : '이진분류'의 **예측 오류**가 얼마인지에 더불어 어떠한 유형의 예측 오류가 발생하고 있는지 함께 나타내는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fake_pred와 실제 결과인 y_test의 Confusion Matrix 출력\n",
    "confusion_matrix(y_test, fake_pred)\n",
    "\n",
    "# TN(거짓이라(0) 예측했고 실제와 일치) --> 405개 / FP(참이라(1) 예측했는데 예측이 틀림(참으로 예측을 하나도 하지 않음 = 0개))\n",
    "# FN(거짓이라(0) 예측했고 실제와 틀림(실제 1인게 45개)) / TP(참이라(1) 예측했고 예측과 일치함 (하지만 참으로 예측을 한게 없음 = 0개)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision)와 재현율(Recall)\n",
    "- 정밀도 : 참이라고 예측한 데이터들 중 실제와 일치하는(실제도 참) 데이터 비율 --> TP / (FP + TP)\n",
    "- 재현율 : 모든 참인 실제값들 중 참으로 예측한 데이터 비율 --> TP / (FN + TP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. MyFakeclassifier의 예측 결과로 정밀도와 재현율 측정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 : 0.0\n",
      "재현율 : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('정밀도 :', precision_score(y_test, fake_pred)) #참이라고 예측한 데이터가 없었음  = 0\n",
    "print('재현율 :', recall_score(y_test, fake_pred)) # 참인 데이터(45개)중 참으로 예측한 데이터가 없었음 = 0\n",
    "\n",
    "# 이 두 개의 지표로 인해 정확도를 평가지표로 사용하는건 부적절 했음을 알 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 업무에 따른 재현율과 정밀도의 상대적 중요도 \n",
    "- 정밀도가 상대적으로 더 중요한 지표인 경우 : 실제 거짓(음성)인 데이터 예측을 참으로(양성) 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "    - ex) 스팸메일 \n",
    "- 재현율이 상대적으로 더 중요한 지표인 경우 : 실제 참인 (양성) 데이터 예측을 부정(음성)으로 잘못판단하게 되면 업무상 큰 영향이 발생하는 경우 \n",
    "    - ex) 암진단, 금융사기 판별 \n",
    "- **불균형한 레이블 클래스를 가지는 이진분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 매우 적은 수의 결과 값에 positive를 설정해 \\\n",
    "1값을 부여, 그렇지 않은 경우는 negative로 0값을 부여**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

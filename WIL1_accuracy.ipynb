{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도의 문제점 살펴보기\n",
    "**정확도(Acuuracy)** = 예측 결과가 동일한 데이터 건수 / 모든 예측 데이터 건수\n",
    "- 불균형한 레이블값 분포에서 ML 모델의 선능을 판단할 경우 적합한 지표가 아님\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 레이블값이 골고루 분포 돼있는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('c:/my_web/machine_lecture/titanic_train.csv')\n",
    "titanic.head()\n",
    "print(titanic['Sex'].value_counts())\n",
    "print()\n",
    "print(titanic['Survived'].value_counts()) # 레이블 값이 고루 분포 돼있음 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanic 데이터에서 남성(1)은 사망(0), 여성(0)은 생존(1)으로 예측하는 **이진분류기** 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator) :\n",
    "    # fit() 메소드는 아무것도 학습하지 않음 \n",
    "    def fit(self, X, y = None) :\n",
    "        pass\n",
    "    \n",
    "    # predict() 메소드는 단순히 sex feature가 남자(1)이면 사망(0), 여자(0)이면 생존(1)으로 예측\n",
    "    def predict(self, X) :\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1 :\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        return pred\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 처리 함수\n",
    "def fillna(df) :\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "# 불필요한 속성 제거하는 함수 \n",
    "def drop_features(df) :\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "# 인코딩 함수 \n",
    "def enco_features(df) :\n",
    "    df['Cabin'] = df['Cabin'].str[:1] # 맨 앞 알파벳만 가져오기\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에 생성한 함수 전부 불러오는 전처리 함수 생성\n",
    "def process_features(df) :\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = enco_features(df)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩, 가공, 학습, 예측, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 :  0.8296\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "titanic = pd.read_csv('c:/my_web/machine_lecture/titanic_train.csv')\n",
    "data = titanic.drop('Survived', axis = 1)\n",
    "target = titanic['Survived']\n",
    "\n",
    "# 전처리 \n",
    "data = process_features(data)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 11,\n",
    "                                                    stratify = target)\n",
    "\n",
    "# 데이터 학습 \n",
    "mdc = MyDummyClassifier()\n",
    "mdc.fit(X_train, y_train) \n",
    "\n",
    "# 예측\n",
    "pred = mdc.predict(X_test) \n",
    "\n",
    "# 평가 \n",
    "print('Dummy Classifier의 정확도는 : {0: .4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 레이블 값 분포가 불균형한 경우"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 전부 0으로 분류(예측)되는 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFakeClassifier(BaseEstimator) :\n",
    "    def fit(self, X, y) :\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X) :\n",
    "        return np.zeros((len(X), 1), dtype = bool)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런의 내장 데이터셋인 load_digits()를 이용하여 MNIST데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "data.shape : (1797, 64)\n",
      "\n",
      "[0 1 2 ... 8 9 8]\n",
      "target.shape : (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print('data.shape :', digits.data.shape)\n",
    "print()\n",
    "print(digits.target)\n",
    "print('target.shape :', digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "1    182\n",
       "5    182\n",
       "4    181\n",
       "6    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.DataFrame(digits.target)\n",
    "df_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- digits번호가 7번이면 **True**이고 --> **1**로 변환\n",
    "- 7이 아니면 **False**이고 --> **0**으로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (digits.target == 7).astype(int)\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y,\n",
    "                                                    random_state = 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블 데이터 분포도 확인 --> 불균형함을 알 수 있음 (0이 훨씬 많음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 종속변수 크기 : (450,)\n",
      "테스트 종속변수 0과 1의 분포도 :\n",
      " 0    405\n",
      "1     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('테스트 종속변수 크기 :', y_test.shape)\n",
    "print('테스트 종속변수 0과 1의 분포도 :\\n', pd.Series(y_test).value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MyFakeClassifier로 학습/예측/정확도 평가해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 예측(분류)을 0으로 하여도 정확도는 :  0.900\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "\n",
    "# 예측(분류)\n",
    "fake_pred = fakeclf.predict(X_test) # 데이터가 전부 0으로 예측된다. \n",
    "\n",
    "# 정확도 평가\n",
    "print('모든 예측(분류)을 0으로 하여도 정확도는 : {: .3f}'.format(accuracy_score(y_test, fake_pred)))\n",
    "# 모든 예측을 0으로 하여도 실제 데이터의 분포가 0으로 치우쳐져 있기 때문에 예측과 실제가 일치할 확률이 90퍼나 된다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 결론 : 이진분류 종속변수의 데이터 분포가 한쪽으로 치우칠 경우 (0이나 1로 치우칠 경우) \n",
    "#### 정확도로 평가하는것은 부적절하다.\n",
    "- 정확도의 한계를 보완하기 위한 평가지표를 알아보자"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix (오차행렬)\n",
    "오차행렬 : '이진분류'의 **예측 오류**가 얼마인지에 더불어 어떠한 유형의 예측 오류가 발생하고 있는지 함께 나타내는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fake_pred와 실제 결과인 y_test의 Confusion Matrix 출력\n",
    "confusion_matrix(y_test, fake_pred)\n",
    "\n",
    "# TN(거짓이라(0) 예측했고 실제와 일치) --> 405개 / FP(참이라(1) 예측했는데 예측이 틀림(참으로 예측을 하나도 하지 않음 = 0개))\n",
    "# FN(거짓이라(0) 예측했고 실제와 틀림(실제 1인게 45개)) / TP(참이라(1) 예측했고 예측과 일치함 (하지만 참으로 예측을 한게 없음 = 0개)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision)와 재현율(Recall)\n",
    "- 정밀도 : 참이라고 예측한 데이터들 중 실제와 일치하는(실제도 참) 데이터 비율 --> TP / (FP + TP)\n",
    "- 재현율 : 모든 참인 실제값들 중 참으로 예측한 데이터 비율 --> TP / (FN + TP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. MyFakeclassifier의 예측 결과로 정밀도와 재현율 측정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 : 0.0\n",
      "재현율 : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('정밀도 :', precision_score(y_test, fake_pred)) #참이라고 예측한 데이터가 없었음  = 0\n",
    "print('재현율 :', recall_score(y_test, fake_pred)) # 참인 데이터(45개)중 참으로 예측한 데이터가 없었음 = 0\n",
    "\n",
    "# 이 두 개의 지표로 인해 정확도를 평가지표로 사용하는건 부적절 했음을 알 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 업무에 따른 재현율과 정밀도의 상대적 중요도 \n",
    "- 정밀도가 상대적으로 더 중요한 지표인 경우 : 실제 거짓(음성)인 데이터 예측을 참으로(양성) 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "    - ex) 스팸메일 \n",
    "- 재현율이 상대적으로 더 중요한 지표인 경우 : 실제 참인 (양성) 데이터 예측을 부정(음성)으로 잘못판단하게 되면 업무상 큰 영향이 발생하는 경우 \n",
    "    - ex) 암진단, 금융사기 판별 \n",
    "- **불균형한 레이블 클래스를 가지는 이진분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 매우 적은 수의 결과 값에 positive를 설정해 \\\n",
    "1값을 부여, 그렇지 않은 경우는 negative로 0값을 부여**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 정밀도 / 재현율 트레이드오프(Trade off)\n",
    "- 분류하려는 업무 특성상 정밀도 또는 재현율이 특히 강조돼야 할 경우, 분류의 결정임계값(Threshold)을 조정 -> 정밀도 / 재현율 수치를 높일 수 있음\n",
    "- 정밀도와 재현율은 상호 보완적인 평가지표이기 때문에 어느 한 쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬움 (Trade off 관계)\n",
    "- 정밀도를 100% 로 만드는 방법\n",
    "    - 정밀도 = TP / (TP + FP)\n",
    "    - 확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 전부 Negative로 예측 \n",
    "    - 전체 환자 중 확실한 Positive 징후만 가진 환자는 단 1명, 나머지는 전부 Negative로 예측하더라도 FP=0, TP는 1이 되므로 정밀도는 100%가 됨\n",
    "- 재현율을 100%로 만드는 방법\n",
    "    - 모든 환자를 Positive로 예측 \n",
    "    - 재현율 TP / (TP + FN) -> 전체 환자 1000명을 모두 Positive로 예측 \n",
    "    - 이 중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 (FN은 아예 0이므로) 30/(30+0) -> 100%가 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba 의 shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      " : [[0.11874481 0.88125519]\n",
      " [0.91024039 0.08975961]\n",
      " [0.13826762 0.86173238]]\n",
      "\n",
      "두 개의 class중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.11874481 0.88125519 1.        ]\n",
      " [0.91024039 0.08975961 0.        ]\n",
      " [0.13826762 0.86173238 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# pred_proba()메소드 확인\n",
    "pred_proba = lr.predict_proba(X_test)\n",
    "pred = lr.predict(X_test)\n",
    "print('pred_proba 의 shape :', pred_proba.shape)\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n :', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결과 array를 concatenate하여 예측 확률과 결과값을 한 눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('\\n두 개의 class중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binarizer 활용 \n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1, -1, 2],\n",
    "     [2, 0, 0],\n",
    "     [0, 1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값 이하면 0, 보다크면 1 반환 \n",
    "binarizer = Binarizer(threshold = 1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[89 17]\n",
      " [19 54]]\n",
      "\n",
      "정확도 :  0.7989 \n",
      "정밀도 :  0.7606 \n",
      "재현율 :  0.7397\n"
     ]
    }
   ],
   "source": [
    "# 분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 반환\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값. 분류결정 임곗값임. \n",
    "custom_threshold = 0.5\n",
    "\n",
    "#predict_proba() 반환값의 두 번째 컬럼, 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[89 17]\n",
      " [19 54]]\n",
      "\n",
      "정확도 :  0.7989 \n",
      "정밀도 :  0.7606 \n",
      "재현율 :  0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('\\n정확도 : {0: .4f} \\n정밀도 : {1: .4f} \\n재현율 : {2: .4f}'.format(accuracy, precision, recall))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "titanic_df = pd.read_csv('c:/my_web/machine_lecture/titanic_train.csv')\n",
    "data = titanic_df.drop('Survived', axis = 1)\n",
    "target = titanic_df['Survived']\n",
    "data = process_features(data) # 전처리\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                    test_size = 0.20,\n",
    "                                                    random_state = 1)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "get_clf_eval(y_test, pred_lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "- 정밀도와 재현율을 결합한 지표\n",
    "- 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐\n",
    "- F1 = 2 * (precision * recall)/(precision + recall)\n",
    "- ex)\n",
    "    - A예측 모델의 경우 정밀도 0.9 재현율 0.1로 극단적인 차이가남\n",
    "    - B예측 모들은 정밀도 0.5, 재현율 0.5로 큰 차이가 없음 \n",
    "    - A예측 모델의 F1스코어는 0.18이고, B예측 모델의 F1스코어는 0.5로 B모델이 A모델에 비해 F1스코어가 우수함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
